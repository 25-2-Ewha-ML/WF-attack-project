# -*- coding: utf-8 -*-
"""RF_mon+unmon_features_2_open_world_multi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nJ2yD0nKY-10P1IRSZlTMH5KcXs1DNsw
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import optuna
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score
from collections import defaultdict

# 데이터 로드
# 1-1. Monitored 데이터 (기존 95개 웹사이트 데이터)
MONITORED_PATH = 'data/preprocessed/monitored_features_2.csv'
df_monitored = pd.read_csv(MONITORED_PATH)

# 1-2. Unmonitored 데이터 (label이 -1인 상태)
UNMONITORED_PATH = 'data/preprocessed/unmonitored_features_2.csv'
df_unmonitored = pd.read_csv(UNMONITORED_PATH)

# 1-3. 데이터 병합
df = pd.concat([df_monitored, df_unmonitored], axis=0, ignore_index=True)

print(f"전체 데이터 개수: {len(df)}")

# 피처/라벨 분리
y = df["label"]

# X 만들기
X = df.drop(columns=["label"])
print(f"사용 피처 수: {X.shape[1]}")

feature_names = X.columns.tolist()
print(f"사용된 피쳐 목록: {feature_names}")

# 학습/검증 분할
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y
)
print(f"Train/Test 분할 완료. Train 수: {len(X_train)}, Test 수: {len(X_test)}")

def objective(trial):
    """
    Optuna가 실행할 목적 함수
    : 이 함수 안에서 모델을 만들고, 교차 검증 점수를 반환하면 Optuna가 점수를 높이는 방향으로 파라미터를 계속 수정
    """
    # 1. 탐색 공간(Search Space) 정의
    param = {
        'n_estimators': trial.suggest_int('n_estimators', 100, 350),
        'max_depth': trial.suggest_int('max_depth', 10, 25),
        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),
        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),
        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),
        'random_state': 42,
        'n_jobs': -1
    }

    # 2. 모델 생성
    model = RandomForestClassifier(**param)

    # 3. 교차 검증 (Cross Validation)
    # f1_macro: 데이터 불균형을 고려한 F1 점수의 평균
    scores = cross_val_score(model, X_train, y_train, cv=3, scoring='f1_macro')

    # 점수의 평균 반환
    return scores.mean()

print("Optuna 최적화 시작... (잠시만 기다려주세요)")

# 최적화 수행 (n_trials는 시도 횟수)
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=50)

print("\n=== 최적화 완료 ===")
best_params = study.best_trial.params
print(f"Best F1 Score (CV): {study.best_value:.4f}")
print(f"Best Hyperparameters: {best_params}")

# 1. 최적의 파라미터로 최종 모델 재학습
final_model = RandomForestClassifier(**best_params, random_state=42)
final_model.fit(X_train, y_train)

# 2. 테스트 데이터로 예측 수행
y_pred = final_model.predict(X_test)

# 3. 성능 평가
acc = accuracy_score(y_test, y_pred)
f1_macro = f1_score(y_test, y_pred, average='macro')
prec_macro = precision_score(y_test, y_pred, average="macro", zero_division=0)
recall_macro = recall_score(y_test, y_pred, average="macro", zero_division=0)

# Confusion Matrix 추출
cm = confusion_matrix(y_test, y_pred)

# False Positive Rate 계산
metrics_per_class = defaultdict(lambda: {'TP': 0, 'FP': 0, 'TN': 0, 'FN': 0})
unique_labels = sorted(y_test.unique())

for label in unique_labels:
    y_true_binary = (y_test == label).astype(int)
    y_pred_binary = (y_pred == label).astype(int)
    cm = confusion_matrix(y_true_binary, y_pred_binary)
    if cm.size == 4:
        TN, FP, FN, TP = cm.ravel()
        FPR = FP / (FP + TN) if (FP + TN) != 0 else 0.0
        metrics_per_class[label]['FPR'] = FPR
    else:
        metrics_per_class[label]['FPR'] = 0.0

all_fprs = [metrics_per_class[label]['FPR'] for label in unique_labels]
fpr_macro = np.mean(all_fprs)

print("\n\n=== Best Params (Final Optimal Model) ===")
for param_name, param_value in best_params.items():
    print(f" - {param_name:<20} : {param_value}")

print("\n=== Test Metrics ===")
print(f"Accuracy                  : {acc:.4f}")
print(f"Precision (macro)         : {prec_macro:.4f}")
print(f"Recall (TPR, macro)       : {recall_macro:.4f}")
print(f"F1-score (macro)          : {f1_macro:.4f}")
print(f"False Positive Rate (FPR) : {fpr_macro:.4f}")

print("\n=== Classification Report (per class) ===")
print(classification_report(y_test, y_pred, zero_division=0))

import numpy as np
import pandas as pd

# 1. Feature Importance 계산 (이미 되어 있음)
importances = final_model.feature_importances_

# 2. 중요도 순으로 정렬하기 위한 인덱스 생성 (이미 되어 있음)
indices = np.argsort(importances)[::-1]

# 3. 상위 10개 피처만 추출하여 DataFrame 생성
TOP_N = 10

# 상위 10개 피처 이름 및 중요도 값 추출
top_n_features = [feature_names[i] for i in indices[:TOP_N]]
top_n_importances = importances[indices[:TOP_N]]

# DataFrame 생성 (STD 열 제외)
importance_df = pd.DataFrame({
    'feature': top_n_features,
    'importance_mean': top_n_importances
})

# 4. 테이블 형식으로 출력 (Pandas의 to_string 활용)
print(f"=== Top {TOP_N} Features by Feature Importance ===")
# index=False: 행 번호(인덱스)를 출력하지 않음
# float_format: 소수점 이하 6자리까지 출력
print(importance_df.to_string(index=False, float_format='%.6f'))

# 5. Confusion Matrix 시각화
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix (Final Best Model)')
plt.ylabel('Actual Label')
plt.xlabel('Predicted Label')
plt.show()

# 5. Feature Importance (피쳐 중요도) 시각화
importances = final_model.feature_importances_
# 중요도 순으로 정렬하기 위한 인덱스 생성
indices = np.argsort(importances)[::-1]

plt.figure(figsize=(12, 6))
plt.title("Feature Importances")
plt.bar(range(len(feature_names)), importances[indices], align="center")
# X축 레이블을 정렬된 피쳐 이름으로 설정
plt.xticks(range(len(feature_names)), [feature_names[i] for i in indices], rotation=45, ha='right')
plt.xlim([-1, len(feature_names)])
plt.tight_layout()
plt.show()

# --- 결과 해석 작성을 위한 텍스트 출력 ---
top_3_features = [feature_names[i] for i in indices[:3]]
